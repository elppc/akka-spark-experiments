app {
  hour-zone-offset = 0
  data-source{
    top-k-location {
      keyspace="reactive_ocam"
      table="geoloc_cdr"
    }
    usage-kpi{
      keyspace="reactive_ocam"
      table="geoloc_cdr"
    }
  }
}
# HTTP Configurations
http {
  interface = "192.168.56.101"
  port = 8081
  timeout = 5
}
akka{
  # Loggin
  loglevel = DEBUG

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
  }

  cluster {
    log-info = on
    roles = ["queryApiNodeGuardian"]
    gossip-interval = 5s
    publish-stats-interval = 10s
    auto-down-unreachable-after = 10s
    metrics.enabled=off
    metrics.gossip-interval = 10s
    metrics.collect-interval = 10s
    seed-nodes=[]
  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      port = 0
      hostname = "127.0.0.1"
    }
  }
  supervision  {
    max-nb-retries=10
  }
  extensions=["akka.cluster.metrics.ClusterMetricsExtension"]
}

spark{
  master = "local[*]"
  driver-memory = "512m"
  driver-cores = "1"
  mesos {
    executor-home = "/opt/spark-1.6.1"
    coarse = "true"
    cores-max = "7"
    executors-cores = "1"
  }
  executor-memory = "2g"
  default-parallelism = "12"
  cleaner-ttl = "7200"
  streaming-batch-interval = 1000
  checkpoint-dir = "/tmp/spark/checkpoint"
  event-log-dir="/srv/spark/log"
  event-log-enabled = "true"
  jars ="/opt/lib/"
}

cassandra{
  cassandraHosts = "127.0.0.1"
  auth-username = ""
  auth-password = ""
  keep-alive = 1000
  retry-count = 10
  connection-reconnect-delay-min = 1000
  connection-reconnect-delay-max = 60000
  read {
    page-row-size = 1000
    consistency-level = "LOCAL_ONE"
    split-size = 100000
  }
  write{
    parallelism-level = 5
    batch-size-bytes = 65536
    batch-size-rows = "auto"
    consistency-level = "LOCAL_ONE"
    default-measured-inserts-count = 128
  }
}

akka.cluster.seed.zookeeper {
  url = "127.0.0.1:2181"
  path = "/ingestApi/cluster/seed"
  authorization {
    //scheme = "digest"
    //auth = ":"
  }
}